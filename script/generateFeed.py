#!/usr/bin/env python3
import json
from datetime import datetime, timezone

INPUT_FILE = "data.json"
OUTPUT_FILE = "feed.xml"

def format_rfc822(dt: datetime):
    dt_utc = dt.astimezone(timezone.utc)
    return dt_utc.strftime("%a, %d %b %Y %H:%M:%S %z")

def format_duration(total_minutes: int):
    hours, minutes = divmod(total_minutes, 60)
    return f"{hours:02}:{minutes:02}:00"

def build_description(ep):
    lines = [ep["episode_url"], "", ep["synopsis"].strip(), ""]
    for act in ep.get("acts", []):
        lines.append(act["number_text"] if act["number_text"] != "Prologue" else "Prologue")
        summary_line = act["summary"].strip()
        if act.get("duration"):
            summary_line += f" ({act['duration']} minutes)"
        if act.get("contributors"):
            summary_line += " by " + ", ".join(act["contributors"])
        lines.append(summary_line)
        lines.append("")
    lines.append(f"Originally Aired: {datetime.strptime(ep['original_air_date'], '%a, %d %b %Y %H:%M:%S %z').strftime('%Y-%m-%d')}")
    full_desc = "\n".join(lines)
    return f"<![CDATA[{full_desc}]]>"

def build_item(ep, latest_pub_dt, clean=False):
    padded_number = ep["number"].zfill(4)
    orig_dt = datetime.strptime(ep["original_air_date"], "%a, %d %b %Y %H:%M:%S %z")
    is_repeat = latest_pub_dt.year != orig_dt.year
    title_suffix = " - Repeat" if is_repeat else ""
    description = build_description(ep)
    total_minutes = sum((act.get("duration") or 0) for act in ep.get("acts", []))
    guid_suffix = "-C" if clean else ""
    explicit_val = "clean" if clean else ("yes" if ep.get("download_clean") else "yes")
    download_url = ep["download_clean"] if clean else ep["download"]
    guid = f"{padded_number}-{latest_pub_dt.strftime('%Y%m%d')}{guid_suffix}"

    item = f"""    <item>
      <title>{ep["number"]}: {ep["title"]}{title_suffix}{' (Clean)' if clean else ''}</title>
      <link>{ep["episode_url"]}</link>
      <guid>{guid}</guid>
      <itunes:season>{orig_dt.year}</itunes:season>
      <itunes:episode>{ep["number"]}</itunes:episode>
      <itunes:episodeType>full</itunes:episodeType>
      <itunes:explicit>{explicit_val}</itunes:explicit>
      <description>{description}</description>
      <pubDate>{format_rfc822(latest_pub_dt)}</pubDate>
      <enclosure url="{download_url}" type="audio/mpeg"/>
      <itunes:duration>{format_duration(total_minutes)}</itunes:duration>"""
    if ep.get("image") and ep["image"].get("url"):
        item += f'\n      <itunes:image href="{ep["image"]["url"]}"/>'
    item += "\n    </item>"
    return item

def main():
    with open(INPUT_FILE, "r", encoding="utf-8") as f:
        episodes = json.load(f)

    items = []
    for ep in episodes:
        if not ep.get("download"):
            continue
        latest_pub_str = max(ep.get("published_dates", []),
                             key=lambda x: datetime.strptime(x, "%a, %d %b %Y %H:%M:%S %z"))
        latest_pub_dt = datetime.strptime(latest_pub_str, "%a, %d %b %Y %H:%M:%S %z")
        # Normal version
        items.append(build_item(ep, latest_pub_dt, clean=False))
        # Clean version if exists
        if ep.get("download_clean"):
            items.append(build_item(ep, latest_pub_dt, clean=True))

    # Sort descending by pubDate
    items.sort(key=lambda x: datetime.strptime(
        x.split("<pubDate>")[1].split("</pubDate>")[0], "%a, %d %b %Y %H:%M:%S %z"), reverse=True)

    rss_header = """<?xml version="1.0" ?>
<rss xmlns:itunes="http://www.itunes.com/dtds/podcast-1.0.dtd" version="2.0">
  <channel>
    <title>That American Archive</title>
    <link>https://www.thisamericanlife.org</link>
    <description>Autogenerated feed of the This American Life archive with explicit and clean episodes.</description>
    <language>en</language>
    <copyright>Copyright Â© Ira Glass / This American Life</copyright>
    <itunes:image href="https://i.imgur.com/pTMCfn9.png"/>"""

    rss_footer = "  </channel>\n</rss>"

    with open(OUTPUT_FILE, "w", encoding="utf-8") as f:
        f.write(rss_header + "\n")
        f.write("\n".join(items) + "\n")
        f.write(rss_footer + "\n")

if __name__ == "__main__":
    main()
